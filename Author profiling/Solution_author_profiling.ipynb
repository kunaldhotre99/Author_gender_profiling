{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 58 ADA Gender Classification Assignment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost\n",
    "#!pip install -U scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from xml.etree import ElementTree\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import nltk\n",
    "import time\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_labels.csv\")\n",
    "test = pd.read_csv(\"test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d7d392835f50664fc079f0f388e147a0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ee40b86368137b86f51806c9f105b34b</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>919bc742d9a22d65eab1f52b11656cab</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15b97a08d65f22d97ca685686510b6ae</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>affa98421ef5c46ca7c8f246e0a134c1</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  gender\n",
       "0  d7d392835f50664fc079f0f388e147a0    male\n",
       "1  ee40b86368137b86f51806c9f105b34b  female\n",
       "2  919bc742d9a22d65eab1f52b11656cab    male\n",
       "3  15b97a08d65f22d97ca685686510b6ae  female\n",
       "4  affa98421ef5c46ca7c8f246e0a134c1  female"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d6b08022cdf758ead05e1c266649c393</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9a989cb04766d5a89a65e8912d448328</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a1053a059d58fbafd3e782a8f7972c0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6032537900368aca3d1546bd71ecabd1</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d191280655be8108ec9928398ff5b563</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  gender\n",
       "0  d6b08022cdf758ead05e1c266649c393    male\n",
       "1  9a989cb04766d5a89a65e8912d448328  female\n",
       "2  2a1053a059d58fbafd3e782a8f7972c0    male\n",
       "3  6032537900368aca3d1546bd71ecabd1    male\n",
       "4  d191280655be8108ec9928398ff5b563    male"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading IDs from train and test to extract comments from the XML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training_data_comment = []\n",
    "training_data_gender = train['gender'].tolist()\n",
    "training_data_ids = []\n",
    "for ids in train['id']:\n",
    "    \n",
    "    gender = str(train[train[\"id\"] == ids]['gender'])    \n",
    "    \n",
    "    file_name = \".\\\\data\\\\\" + str(ids) + \".xml\"\n",
    "    \n",
    "    xml_obj = ElementTree.parse(file_name)\n",
    "    \n",
    "    comments = xml_obj.findall('documents/document')\n",
    "    comment_list = []\n",
    "    for com in comments:\n",
    "        comment_list.append(com.text)\n",
    "    comm = \".\".join(comment_list)\n",
    "    training_data_comment.append(comm)\n",
    "    training_data_ids.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_data_comment = []\n",
    "test_data_gender = test['gender'].tolist()\n",
    "test_data_ids = []\n",
    "for ids in test['id']:    \n",
    "    \n",
    "    file_name = \".\\\\data\\\\\" + str(ids) + \".xml\"\n",
    "    \n",
    "    xml_obj = ElementTree.parse(file_name)\n",
    "    \n",
    "    test_comments = xml_obj.findall('documents/document')\n",
    "    test_comment_list = []\n",
    "    \n",
    "    for com in test_comments:\n",
    "        test_comment_list.append(com.text)\n",
    "        \n",
    "    comm = \".\".join(test_comment_list)\n",
    "    \n",
    "    test_data_comment.append(comm)\n",
    "\n",
    "    test_data_ids.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {'id': training_data_ids, 'tweets': training_data_comment, 'gender': training_data_gender}\n",
    "train = pd.DataFrame(train)\n",
    "test = {'id': test_data_ids, 'tweets': test_data_comment, 'gender': test_data_gender}\n",
    "test = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweets</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d7d392835f50664fc079f0f388e147a0</td>\n",
       "      <td>@CSIFERROSCAN youch! Good things to know! Is t...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ee40b86368137b86f51806c9f105b34b</td>\n",
       "      <td>Donald the Menace #ThanksComey  https://t.co/j...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>919bc742d9a22d65eab1f52b11656cab</td>\n",
       "      <td>This seems super sketch / too good to be true:...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15b97a08d65f22d97ca685686510b6ae</td>\n",
       "      <td>Just some texts with my dad about our Saturday...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>affa98421ef5c46ca7c8f246e0a134c1</td>\n",
       "      <td>Irrevocably love this talented human and so pr...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  d7d392835f50664fc079f0f388e147a0   \n",
       "1  ee40b86368137b86f51806c9f105b34b   \n",
       "2  919bc742d9a22d65eab1f52b11656cab   \n",
       "3  15b97a08d65f22d97ca685686510b6ae   \n",
       "4  affa98421ef5c46ca7c8f246e0a134c1   \n",
       "\n",
       "                                              tweets  gender  \n",
       "0  @CSIFERROSCAN youch! Good things to know! Is t...    male  \n",
       "1  Donald the Menace #ThanksComey  https://t.co/j...  female  \n",
       "2  This seems super sketch / too good to be true:...    male  \n",
       "3  Just some texts with my dad about our Saturday...  female  \n",
       "4  Irrevocably love this talented human and so pr...  female  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweets</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d6b08022cdf758ead05e1c266649c393</td>\n",
       "      <td>@JJMSports what odds he stops whining and goes...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9a989cb04766d5a89a65e8912d448328</td>\n",
       "      <td>Bingay!!!! I won a cool handy tonight #cashmon...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a1053a059d58fbafd3e782a8f7972c0</td>\n",
       "      <td>The cynical manipulation of voters' desire for...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6032537900368aca3d1546bd71ecabd1</td>\n",
       "      <td>@9NowAU cannot convert b to object... on Sony ...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d191280655be8108ec9928398ff5b563</td>\n",
       "      <td>Cat Is a Kneading Maniac – Floppycats https://...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  d6b08022cdf758ead05e1c266649c393   \n",
       "1  9a989cb04766d5a89a65e8912d448328   \n",
       "2  2a1053a059d58fbafd3e782a8f7972c0   \n",
       "3  6032537900368aca3d1546bd71ecabd1   \n",
       "4  d191280655be8108ec9928398ff5b563   \n",
       "\n",
       "                                              tweets  gender  \n",
       "0  @JJMSports what odds he stops whining and goes...    male  \n",
       "1  Bingay!!!! I won a cool handy tonight #cashmon...  female  \n",
       "2  The cynical manipulation of voters' desire for...    male  \n",
       "3  @9NowAU cannot convert b to object... on Sony ...    male  \n",
       "4  Cat Is a Kneading Maniac – Floppycats https://...    male  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      1552\n",
       "female    1548\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_counts = train['gender'].value_counts()\n",
    "gender_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The number of male and female columns are almost the same. We can go ahead without trimming the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a list of nltk stop words\n",
    "\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'e']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a list of alphabets\n",
    "\n",
    "alphabet_string = string.ascii_lowercase\n",
    "alphabet_string = list(alphabet_string)\n",
    "alphabet_string[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we']\n",
      "['v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# adding the two lists to create a list of stop words\n",
    "\n",
    "stopwords_list = stopwords_list + alphabet_string\n",
    "print(stopwords_list[:5])  # stop words from nltk\n",
    "print(stopwords_list[-5:])  # stop words (length 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to a list for ease in manipulation\n",
    "tweets = train['tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# using regular expressions to remove unwanted words\n",
    "tweets = tweets.apply(lambda x: re.sub(r\"http\\S+|www\\S+\",\" \",x))\n",
    "# converting to lower case\n",
    "tweets = tweets.apply(lambda x: x.lower())\n",
    "\n",
    "# creating a tokeniser to split the words\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tweets = tweets.apply(lambda x: tokenizer.tokenize(x))\n",
    "\n",
    "# converting all non alpha values to none\n",
    "tweets = [[v for v in tweet if v.isalpha()]for tweet in tweets]\n",
    "\n",
    "# lemmatising the words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tweets = [[lemmatizer.lemmatize(token) for token in tweet] for tweet in tweets]\n",
    "\n",
    "# removing the stopwords from the list created above\n",
    "tweets = [[token for token in tweet if token not in stopwords_list] for tweet in tweets]\n",
    "\n",
    "# creating a corpus for train\n",
    "train_corpus = []\n",
    "for item in tweets:\n",
    "    item = ' '.join(item)\n",
    "    train_corpus.append(item)\n",
    "\n",
    "# forming them to text from list of words and updating the train data frame\n",
    "train['tweets'] = tweets\n",
    "train['tweets'] = train['tweets'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweets</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d7d392835f50664fc079f0f388e147a0</td>\n",
       "      <td>csiferroscan youch good thing know sort stuff ...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ee40b86368137b86f51806c9f105b34b</td>\n",
       "      <td>donald menace thankscomey return national grea...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>919bc742d9a22d65eab1f52b11656cab</td>\n",
       "      <td>seems super sketch good true legit invisible r...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15b97a08d65f22d97ca685686510b6ae</td>\n",
       "      <td>text dad saturday night plan westernbulldogs t...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>affa98421ef5c46ca7c8f246e0a134c1</td>\n",
       "      <td>irrevocably love talented human proud tote sla...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  d7d392835f50664fc079f0f388e147a0   \n",
       "1  ee40b86368137b86f51806c9f105b34b   \n",
       "2  919bc742d9a22d65eab1f52b11656cab   \n",
       "3  15b97a08d65f22d97ca685686510b6ae   \n",
       "4  affa98421ef5c46ca7c8f246e0a134c1   \n",
       "\n",
       "                                              tweets  gender  \n",
       "0  csiferroscan youch good thing know sort stuff ...    male  \n",
       "1  donald menace thankscomey return national grea...  female  \n",
       "2  seems super sketch good true legit invisible r...    male  \n",
       "3  text dad saturday night plan westernbulldogs t...  female  \n",
       "4  irrevocably love talented human proud tote sla...  female  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to a list for ease in manipulation\n",
    "tweets = test['tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# using regular expressions to remove unwanted words\n",
    "tweets = tweets.apply(lambda x: re.sub(r\"http\\S+|www\\S+\",\" \",x))\n",
    "# converting to lower case\n",
    "tweets = tweets.apply(lambda x: x.lower())\n",
    "\n",
    "# creating a tokeniser to split the words\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tweets = tweets.apply(lambda x: tokenizer.tokenize(x))\n",
    "\n",
    "# converting all non alpha values to none\n",
    "tweets = [[v for v in tweet if v.isalpha()]for tweet in tweets]\n",
    "\n",
    "# lemmatising the words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tweets = [[lemmatizer.lemmatize(token) for token in tweet] for tweet in tweets]\n",
    "\n",
    "# removing the stopwords from the list created above\n",
    "tweets = [[token for token in tweet if token not in stopwords_list] for tweet in tweets]\n",
    "\n",
    "# creating a corpus for test\n",
    "test_corpus = []\n",
    "for item in tweets:\n",
    "    item = ' '.join(item)\n",
    "    test_corpus.append(item)\n",
    "\n",
    "\n",
    "# forming them to text from list of words and updating the test data frame\n",
    "test['tweets'] = tweets\n",
    "test['tweets'] = test['tweets'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweets</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d6b08022cdf758ead05e1c266649c393</td>\n",
       "      <td>jjmsports odds stop whining go get proper job ...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9a989cb04766d5a89a65e8912d448328</td>\n",
       "      <td>bingay cool handy tonight cashmoney howboutdat...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a1053a059d58fbafd3e782a8f7972c0</td>\n",
       "      <td>cynical manipulation voter desire honest gover...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6032537900368aca3d1546bd71ecabd1</td>\n",
       "      <td>cannot convert object sony braavia happening w...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d191280655be8108ec9928398ff5b563</td>\n",
       "      <td>cat kneading maniac floppycats left go hysteri...</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  d6b08022cdf758ead05e1c266649c393   \n",
       "1  9a989cb04766d5a89a65e8912d448328   \n",
       "2  2a1053a059d58fbafd3e782a8f7972c0   \n",
       "3  6032537900368aca3d1546bd71ecabd1   \n",
       "4  d191280655be8108ec9928398ff5b563   \n",
       "\n",
       "                                              tweets  gender  \n",
       "0  jjmsports odds stop whining go get proper job ...    male  \n",
       "1  bingay cool handy tonight cashmoney howboutdat...  female  \n",
       "2  cynical manipulation voter desire honest gover...    male  \n",
       "3  cannot convert object sony braavia happening w...    male  \n",
       "4  cat kneading maniac floppycats left go hysteri...    male  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the tfidf vectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer='word',input='content',\n",
    "                           lowercase=False,                   # make the text lowercase\n",
    "                           min_df=0.05,                      # remove words appearing in less than 5% of the documents\n",
    "                           max_df=0.95,                      # remove words appearing in more than 95% of the documents\n",
    "                           use_idf=True,\n",
    "                           ngram_range=(1,2),               # creates bigrams and unigrams\n",
    "                           max_features = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>acting</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yup</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037598</td>\n",
       "      <td>0.058260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026568</td>\n",
       "      <td>0.053083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047066</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>0.045574</td>\n",
       "      <td>0.111121</td>\n",
       "      <td>0.043611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3100 rows × 1817 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          able  absolute  absolutely  accept    access  according   account  \\\n",
       "0     0.000000  0.000000    0.000000     0.0  0.000000        0.0  0.000000   \n",
       "1     0.000000  0.000000    0.000000     0.0  0.035843        0.0  0.000000   \n",
       "2     0.000000  0.000000    0.034440     0.0  0.000000        0.0  0.000000   \n",
       "3     0.000000  0.000000    0.035248     0.0  0.000000        0.0  0.000000   \n",
       "4     0.000000  0.000000    0.000000     0.0  0.000000        0.0  0.000000   \n",
       "...        ...       ...         ...     ...       ...        ...       ...   \n",
       "3095  0.000000  0.000000    0.000000     0.0  0.000000        0.0  0.000000   \n",
       "3096  0.000000  0.000000    0.000000     0.0  0.000000        0.0  0.000000   \n",
       "3097  0.000000  0.000000    0.000000     0.0  0.000000        0.0  0.030658   \n",
       "3098  0.045574  0.111121    0.043611     0.0  0.000000        0.0  0.000000   \n",
       "3099  0.000000  0.045315    0.000000     0.0  0.045840        0.0  0.000000   \n",
       "\n",
       "        across  act  acting  ...  yesterday       yet        yo      york  \\\n",
       "0     0.000000  0.0     0.0  ...   0.037598  0.058260  0.000000  0.000000   \n",
       "1     0.000000  0.0     0.0  ...   0.027057  0.000000  0.000000  0.000000   \n",
       "2     0.000000  0.0     0.0  ...   0.000000  0.000000  0.000000  0.000000   \n",
       "3     0.000000  0.0     0.0  ...   0.000000  0.026568  0.053083  0.000000   \n",
       "4     0.000000  0.0     0.0  ...   0.000000  0.000000  0.000000  0.000000   \n",
       "...        ...  ...     ...  ...        ...       ...       ...       ...   \n",
       "3095  0.044991  0.0     0.0  ...   0.000000  0.000000  0.000000  0.000000   \n",
       "3096  0.053801  0.0     0.0  ...   0.000000  0.035318  0.000000  0.000000   \n",
       "3097  0.000000  0.0     0.0  ...   0.000000  0.000000  0.000000  0.000000   \n",
       "3098  0.000000  0.0     0.0  ...   0.000000  0.000000  0.000000  0.062552   \n",
       "3099  0.000000  0.0     0.0  ...   0.000000  0.000000  0.053566  0.000000   \n",
       "\n",
       "         young   youtube        yr  yup   zealand      zero  \n",
       "0     0.041463  0.000000  0.000000  0.0  0.000000  0.000000  \n",
       "1     0.000000  0.000000  0.000000  0.0  0.000000  0.000000  \n",
       "2     0.000000  0.000000  0.000000  0.0  0.000000  0.051348  \n",
       "3     0.037816  0.000000  0.000000  0.0  0.047066  0.000000  \n",
       "4     0.000000  0.000000  0.000000  0.0  0.000000  0.000000  \n",
       "...        ...       ...       ...  ...       ...       ...  \n",
       "3095  0.000000  0.000000  0.050015  0.0  0.000000  0.000000  \n",
       "3096  0.000000  0.049284  0.000000  0.0  0.000000  0.000000  \n",
       "3097  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  \n",
       "3098  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  \n",
       "3099  0.000000  0.000000  0.000000  0.0  0.000000  0.000000  \n",
       "\n",
       "[3100 rows x 1817 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the tfidf for train set\n",
    "tfidftrain = vectorizer.fit_transform(train_corpus)\n",
    "tfidftrain = pd.DataFrame(tfidftrain.todense(), columns=vectorizer.get_feature_names())\n",
    "tfidftrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>acting</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yo</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>yup</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046601</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.031501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098492</td>\n",
       "      <td>0.054988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110720</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033119</td>\n",
       "      <td>0.025660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045458</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1817 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         able  absolute  absolutely    accept    access  according  account  \\\n",
       "0    0.000000  0.034532    0.000000  0.000000  0.000000        0.0      0.0   \n",
       "1    0.000000  0.000000    0.000000  0.000000  0.000000        0.0      0.0   \n",
       "2    0.031501  0.000000    0.000000  0.043292  0.000000        0.0      0.0   \n",
       "3    0.034773  0.000000    0.000000  0.000000  0.042884        0.0      0.0   \n",
       "4    0.000000  0.000000    0.000000  0.000000  0.000000        0.0      0.0   \n",
       "..        ...       ...         ...       ...       ...        ...      ...   \n",
       "495  0.000000  0.000000    0.027640  0.000000  0.000000        0.0      0.0   \n",
       "496  0.000000  0.000000    0.031322  0.000000  0.000000        0.0      0.0   \n",
       "497  0.000000  0.000000    0.000000  0.000000  0.000000        0.0      0.0   \n",
       "498  0.000000  0.000000    0.028710  0.000000  0.000000        0.0      0.0   \n",
       "499  0.000000  0.000000    0.000000  0.000000  0.000000        0.0      0.0   \n",
       "\n",
       "       across  act    acting  ...  yesterday       yet   yo  york     young  \\\n",
       "0    0.000000  0.0  0.000000  ...   0.026369  0.000000  0.0   0.0  0.029079   \n",
       "1    0.000000  0.0  0.000000  ...   0.033952  0.000000  0.0   0.0  0.000000   \n",
       "2    0.000000  0.0  0.000000  ...   0.000000  0.000000  0.0   0.0  0.032340   \n",
       "3    0.000000  0.0  0.000000  ...   0.000000  0.000000  0.0   0.0  0.000000   \n",
       "4    0.000000  0.0  0.052633  ...   0.000000  0.000000  0.0   0.0  0.000000   \n",
       "..        ...  ...       ...  ...        ...       ...  ...   ...       ...   \n",
       "495  0.000000  0.0  0.000000  ...   0.000000  0.000000  0.0   0.0  0.029653   \n",
       "496  0.035963  0.0  0.000000  ...   0.000000  0.000000  0.0   0.0  0.000000   \n",
       "497  0.000000  0.0  0.000000  ...   0.033119  0.025660  0.0   0.0  0.000000   \n",
       "498  0.000000  0.0  0.000000  ...   0.000000  0.064918  0.0   0.0  0.030801   \n",
       "499  0.000000  0.0  0.038867  ...   0.000000  0.020528  0.0   0.0  0.000000   \n",
       "\n",
       "     youtube        yr  yup   zealand      zero  \n",
       "0        0.0  0.000000  0.0  0.000000  0.000000  \n",
       "1        0.0  0.000000  0.0  0.046601  0.000000  \n",
       "2        0.0  0.038477  0.0  0.000000  0.000000  \n",
       "3        0.0  0.000000  0.0  0.000000  0.000000  \n",
       "4        0.0  0.000000  0.0  0.098492  0.054988  \n",
       "..       ...       ...  ...       ...       ...  \n",
       "495      0.0  0.035280  0.0  0.110720  0.000000  \n",
       "496      0.0  0.000000  0.0  0.000000  0.000000  \n",
       "497      0.0  0.000000  0.0  0.045458  0.000000  \n",
       "498      0.0  0.000000  0.0  0.000000  0.000000  \n",
       "499      0.0  0.000000  0.0  0.000000  0.000000  \n",
       "\n",
       "[500 rows x 1817 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the same vectorizer on test data\n",
    "tfidftest = vectorizer.transform(test_corpus)\n",
    "tfidftest = pd.DataFrame(tfidftest.todense(), columns=vectorizer.get_feature_names())\n",
    "tfidftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1817"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of features\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL BUILDING LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building a logistic regression classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(tfidftrain, train[\"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating prediction and true label lists to compare result\n",
    "predicted_labels = classifier.predict(tfidftest)\n",
    "true_labels = test.pop('gender')\n",
    "test['gender'] = predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an encoder for the categorical value output to calculate accuracy, precision and recall\n",
    "le = LabelEncoder()\n",
    "predicted_labels = le.fit_transform(predicted_labels)\n",
    "true_labels = le.fit_transform(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[194  58]\n",
      " [ 41 207]]\n",
      "testing score is: 80.2 %\n",
      "Precision: 0.7811320754716982\n",
      "Recall: 0.8346774193548387\n"
     ]
    }
   ],
   "source": [
    "# printing the confusion matrix, accuracy, Precision and recall\n",
    "confusion_matrix_no_tuning = confusion_matrix(true_labels, predicted_labels) \n",
    "  \n",
    "print (\"Confusion Matrix : \\n\", confusion_matrix_no_tuning)\n",
    "print(\"testing score is:\",accuracy_score(true_labels, predicted_labels)*100,'%')\n",
    "print(\"Precision:\",precision_score(true_labels, predicted_labels))\n",
    "print(\"Recall:\",recall_score(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HYPER PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of values for C i.e., lambda in this case\n",
    "param_grid = [{\"C\": np.logspace(-4,4,1000)\n",
    "             }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1000 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  4.4min finished\n"
     ]
    }
   ],
   "source": [
    "# creating a grid search to find optimum value of lambda\n",
    "clf_wt = GridSearchCV(classifier, param_grid = param_grid, verbose=True,cv=2, n_jobs=-1)\n",
    "classifier_logistic_grid = clf_wt.fit(tfidftrain,train[\"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating predictions after tuning\n",
    "predicted_labels_wt = classifier_logistic_grid.best_estimator_.predict(tfidftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.9243509752303323)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the best parameter\n",
    "classifier_logistic_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the labels for calculating the confusion matrix, accuracy, precision and recall\n",
    "predicted_labels_wt = le.fit_transform(predicted_labels_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[197  55]\n",
      " [ 40 208]]\n",
      "testing score is: 81.0 %\n",
      "Precision: 79.08745247148289 %\n",
      "Recall: 83.87096774193549 %\n"
     ]
    }
   ],
   "source": [
    "# printing the confusion matrix, accuracy, precision and recall\n",
    "confusion_matrix_with_tuning = confusion_matrix(true_labels, predicted_labels_wt) \n",
    "  \n",
    "print (\"Confusion Matrix : \\n\", confusion_matrix_with_tuning)\n",
    "print(\"testing score is:\",accuracy_score(true_labels, predicted_labels_wt)*100,'%')\n",
    "print(\"Precision:\",precision_score(true_labels, predicted_labels_wt)*100,\"%\")\n",
    "print(\"Recall:\",recall_score(true_labels, predicted_labels_wt)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING PREDICTION CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['male', 'female', 'male', 'male', 'male']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting encoded values to actual values\n",
    "text_labels = []\n",
    "for val in predicted_labels_wt:\n",
    "    if val == 1:\n",
    "        text_labels.append('male')\n",
    "    else:\n",
    "        text_labels.append('female')\n",
    "        \n",
    "text_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list for ids\n",
    "ids = test['id']\n",
    "\n",
    "# converting lists to data frame\n",
    "df_encoded = pd.DataFrame(list(zip(ids, predicted_labels_wt)), columns = ['id', 'gender'])\n",
    "df = pd.DataFrame(list(zip(ids, text_labels)), columns = ['id', 'gender'])\n",
    "\n",
    "# converting to CSV\n",
    "# df_encoded.to_csv('pred_labels.csv', header = True, index = False)\n",
    "df.to_csv('pred_labels.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d6b08022cdf758ead05e1c266649c393</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9a989cb04766d5a89a65e8912d448328</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2a1053a059d58fbafd3e782a8f7972c0</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6032537900368aca3d1546bd71ecabd1</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d191280655be8108ec9928398ff5b563</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  gender\n",
       "0  d6b08022cdf758ead05e1c266649c393    male\n",
       "1  9a989cb04766d5a89a65e8912d448328  female\n",
       "2  2a1053a059d58fbafd3e782a8f7972c0    male\n",
       "3  6032537900368aca3d1546bd71ecabd1    male\n",
       "4  d191280655be8108ec9928398ff5b563    male"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
